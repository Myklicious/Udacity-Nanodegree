{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpreting Results of Logistic Regression\n",
    "\n",
    "In this notebook (and quizzes), you will be getting some practice with interpreting the coefficients in logistic regression.  Using what you saw in the previous video should be helpful in assisting with this notebook.\n",
    "\n",
    "The dataset contains four variables: `admit`, `gre`, `gpa`, and `prestige`:\n",
    "\n",
    "* `admit` is a binary variable. It indicates whether or not a candidate was admitted into UCLA (admit = 1) our not (admit = 0).\n",
    "* `gre` is the GRE score. GRE stands for Graduate Record Examination.\n",
    "* `gpa` stands for Grade Point Average.\n",
    "* `prestige` is the prestige of an applicant alta mater (the school attended before applying), with 1 being the highest (highest prestige) and 4 as the lowest (not prestigious).\n",
    "\n",
    "To start, let's read in the necessary libraries and data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   admit  gre   gpa  prestige\n0      0  380  3.61         3\n1      1  660  3.67         3\n2      1  800  4.00         1\n3      1  640  3.19         4\n4      0  520  2.93         4",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>admit</th>\n      <th>gre</th>\n      <th>gpa</th>\n      <th>prestige</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>380</td>\n      <td>3.61</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>660</td>\n      <td>3.67</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>800</td>\n      <td>4.00</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>640</td>\n      <td>3.19</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>520</td>\n      <td>2.93</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "df = pd.read_csv(\"./admissions.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few different ways you might choose to work with the `prestige` column in this dataset.  For this dataset, we will want to allow for the change from prestige 1 to prestige 2 to allow a different acceptance rate than changing from prestige 3 to prestige 4.\n",
    "\n",
    "1. With the above idea in place, create the dummy variables needed to change prestige to a categorical variable, rather than quantitative, then answer quiz 1 below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   admit  gre   gpa  prestige  p_1  p_2  p_3  p_4  intercept\n0      0  380  3.61         3    0    0    1    0          1\n1      1  660  3.67         3    0    0    1    0          1\n2      1  800  4.00         1    1    0    0    0          1\n3      1  640  3.19         4    0    0    0    1          1\n4      0  520  2.93         4    0    0    0    1          1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>admit</th>\n      <th>gre</th>\n      <th>gpa</th>\n      <th>prestige</th>\n      <th>p_1</th>\n      <th>p_2</th>\n      <th>p_3</th>\n      <th>p_4</th>\n      <th>intercept</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>380</td>\n      <td>3.61</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>660</td>\n      <td>3.67</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>800</td>\n      <td>4.00</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>640</td>\n      <td>3.19</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>520</td>\n      <td>2.93</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "prestige = pd.get_dummies(df['prestige'])\n",
    "df['p_1'] = prestige[1]\n",
    "df['p_2'] = prestige[2]\n",
    "df['p_3'] = prestige[3]\n",
    "df['p_4'] = prestige[4]\n",
    "df['intercept'] = 1\n",
    "df.head()\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(0.15365239294710328,\n 0.37279596977329976,\n 0.3047858942065491,\n 0.16876574307304787)"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "df['p_1'].mean(), df['p_2'].mean(), df['p_3'].mean(), df['p_4'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`2.` Now, fit a logistic regression model to predict if an individual is admitted using `gre`, `gpa`, and `prestige` with a baseline of the prestige value of `1`.  Use the results to answer quiz 2 and 3 below.  Don't forget an intercept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Optimization terminated successfully.\n         Current function value: 0.573854\n         Iterations 6\n                           Logit Regression Results                           \n==============================================================================\nDep. Variable:                  admit   No. Observations:                  397\nModel:                          Logit   Df Residuals:                      391\nMethod:                           MLE   Df Model:                            5\nDate:                Sat, 18 Apr 2020   Pseudo R-squ.:                 0.08166\nTime:                        22:01:05   Log-Likelihood:                -227.82\nconverged:                       True   LL-Null:                       -248.08\nCovariance Type:            nonrobust   LLR p-value:                 1.176e-07\n==============================================================================\n                 coef    std err          z      P>|z|      [0.025      0.975]\n------------------------------------------------------------------------------\ngre            0.0022      0.001      2.028      0.043    7.44e-05       0.004\ngpa            0.7793      0.333      2.344      0.019       0.128       1.431\np_1            1.5534      0.417      3.721      0.000       0.735       2.372\np_2            0.8733      0.367      2.378      0.017       0.153       1.593\np_3            0.2147      0.393      0.547      0.584      -0.555       0.984\nintercept     -5.4303      1.140     -4.764      0.000      -7.664      -3.196\n==============================================================================\n"
    }
   ],
   "source": [
    "mod = sm.Logit(df['admit'], df[['gre','gpa','p_1', 'p_2','p_3','intercept']])\n",
    "res = mod.fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Optimization terminated successfully.\n         Current function value: 0.573854\n         Iterations 6\n                           Logit Regression Results                           \n==============================================================================\nDep. Variable:                  admit   No. Observations:                  397\nModel:                          Logit   Df Residuals:                      391\nMethod:                           MLE   Df Model:                            5\nDate:                Sat, 18 Apr 2020   Pseudo R-squ.:                 0.08166\nTime:                        22:01:08   Log-Likelihood:                -227.82\nconverged:                       True   LL-Null:                       -248.08\nCovariance Type:            nonrobust   LLR p-value:                 1.176e-07\n==============================================================================\n                 coef    std err          z      P>|z|      [0.025      0.975]\n------------------------------------------------------------------------------\ngre            0.0022      0.001      2.028      0.043    7.44e-05       0.004\ngpa            0.7793      0.333      2.344      0.019       0.128       1.431\np_2           -0.6801      0.317     -2.146      0.032      -1.301      -0.059\np_3           -1.3387      0.345     -3.882      0.000      -2.015      -0.663\np_4           -1.5534      0.417     -3.721      0.000      -2.372      -0.735\nintercept     -3.8769      1.142     -3.393      0.001      -6.116      -1.638\n==============================================================================\n"
    }
   ],
   "source": [
    "mod = sm.Logit(df['admit'], df[['gre','gpa','p_2', 'p_3','p_4','intercept']])\n",
    "res = mod.fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[4.727516444398727, 2.394800670378709, 1.2394899941851785, 2.1799457692483717]"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "[np.exp(1.5534), np.exp(0.8733), np.exp(0.2147), np.exp(0.7793)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "1.9740751298733883"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "np.exp(1.5534)/np.exp(0.8733)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}